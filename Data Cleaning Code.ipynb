{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Data Cleaning Code.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"zUClO3ExCr4q","colab_type":"code","colab":{}},"source":["#The following shows how the datasets used for analysis were created from the raw datasets for Manhattan\n","#This process was repeated for New Jersey's Data to create a validation data set"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vz7hb5JmCr4v","colab_type":"code","colab":{}},"source":["import pymysql.cursors\n","import numpy as np\n","import pandas as pd\n","\n","# Connect to the database\n","from sqlalchemy import create_engine\n","engine = create_engine(\"mysql+pymysql://root:xxxxxx@localhost/Citibike\"\n","                       .format(user=\"root\",\n","                               pw=\"xxxxxx\",\n","                               db=\"Citibike\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbaIhkxXCr4x","colab_type":"code","colab":{}},"source":["#Add two years of citibike data to Database\n","filename = \"citibike2017-2019.csv\"\n","\n","chunksize = 1000\n","for chunk in pd.read_csv(filename, chunksize=chunksize):\n","    chunk = chunk.rename(columns={'Unnamed: 0':'id', 'start station name':'start_station_name', \n","                                  'end station name': 'end_station_name',\n","                                  'start station latitude': 'start_station_latitude',\n","                                  'start station longitude':'start_station_longitude',\n","                                  'end station latitude': 'end_station_latitude',\n","                                  'end station longitude':'end_station_longitude'\n","                                 })\n","    chunk = chunk.set_index('id')\n","    chunk.to_sql('trips', con = engine, if_exists = 'append');\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJ8r2AMHCr4z","colab_type":"code","colab":{}},"source":["#import zip code features into database\n","file_names = ['zip_age_sex_distribution.csv', 'zip_population_school_distribution.csv', 'zip_transport_by_sex.csv', 'zipcode_attributes.csv']\n","\n","for file in file_names:\n","    df = pd.read_csv(file)\n","    table_name = file.strip('.csv')\n","    print(table_name)\n","    df.to_sql(table_name, con = engine, if_exists = 'replace');"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_esb00CyCr46","colab_type":"code","colab":{}},"source":["#SQL Code 1\n","#See SQL folder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fA4_PBXCr5B","colab_type":"code","colab":{}},"source":["#Get all start stations with their longitudes and latitudes from database\n","connection = pymysql.connect(host='localhost',\n","                            user='root',\n","                            password='xxxxxx',\n","                            database = 'citibike')\n","\n","\n","cursor = connection.cursor()     # get the cursor\n","sql = 'SELECT * FROM all_start_stations'\n","cursor.execute(sql) # select the database\n","data = cursor.fetchall()\n","\n","field_names = [i[0] for i in cursor.description]\n","\n","all_start_stations = pd.DataFrame(data, columns = field_names)\n","\n","\n","\n","#Get all end stations with their longitudes and latitudes from database\n","connection = pymysql.connect(host='localhost',\n","                            user='root',\n","                            password='xxxxxxx',\n","                            database = 'citibike')\n","\n","\n","cursor = connection.cursor()     # get the cursor\n","sql = 'SELECT * FROM all_end_stations'\n","cursor.execute(sql) # select the database\n","data = cursor.fetchall()\n","\n","field_names = [i[0] for i in cursor.description]\n","\n","all_end_stations = pd.DataFrame(data, columns = field_names)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_ObyXyMCr5D","colab_type":"code","colab":{}},"source":["#Reverse geocoding Function\n","api_key = API_KEY\n","import requests\n","\n","def get_zip(lat, long):\n","    try:\n","        base_url = \"https://maps.googleapis.com/maps/api/geocode/json?\"\n","        url = base_url + \"latlng=\" + '{:.2f}'.format(lat) + \",\" + '{:.2f}'.format(long) + \"&key=\" + api_key\n","        response = requests.get(url)\n","        address = response.json()['results'][0]['address_components']\n","        for element in address:\n","            if('postal_code' in element['types']):\n","                zip_code = element['long_name']\n","                break;\n","            else:\n","                zip_code = 0\n","\n","        return zip_code\n","    except:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4M4HUpy-Cr5H","colab_type":"code","colab":{}},"source":["#Get zip codes for each station\n","all_start_stations_with_zip = all_start_stations.copy()\n","all_end_stations_with_zip = all_end_stations.copy()\n","\n","all_start_stations_with_zip['zip'] = all_start_stations.apply(lambda x: get_zip(float(x['latitude']), float(x['longitude'])), axis = 1)\n","all_end_stations_with_zip['zip'] = all_end_stations.apply(lambda x: get_zip(float(x['latitude']), float(x['longitude'])), axis = 1)\n","\n","#Add stations with zip information to database\n","all_start_stations_with_zip.to_sql('all_end_stations_with_zip', con = engine, if_exists = 'replace');\n","all_end_stations_with_zip.to_sql('all_end_stations_with_zip', con = engine, if_exists = 'replace');\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkSOLtFJCr5M","colab_type":"code","colab":{}},"source":["#Sql code 2\n","#See SQL folder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmtygNKLCr5O","colab_type":"code","colab":{}},"source":["#Import datasets from MySQL Database\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","\n","\n","connection = pymysql.connect(host='localhost',\n","                            user='root',\n","                            password='xxxxxx',\n","                            database = 'citibike')\n","\n","#get trips_by_station from database\n","cursor = connection.cursor()     # get the cursor\n","sql = 'SELECT * FROM trips_by_station'\n","cursor.execute(sql) # select the database\n","data = cursor.fetchall()\n","\n","#column names\n","field_names = [i[0] for i in cursor.description]\n","\n","trips_by_station = pd.DataFrame(data, columns = field_names).to_csv('trips_by_station.csv')\n","\n","\n","#get stations_and_features from database\n","cursor = connection.cursor()     # get the cursor\n","sql = 'SELECT * FROM stations_and_features'\n","cursor.execute(sql) # select the database\n","data = cursor.fetchall()\n","\n","#column names \n","field_names = [i[0] for i in cursor.description]\n","\n","stations_and_features= pd.DataFrame(data, columns = field_names).to_csv('stations_and_features.csv')\n","\n","\n","#get trips_to_and_from_with_zips from database\n","cursor = connection.cursor()     # get the cursor\n","sql = 'SELECT * FROM trips_to_and_from_with_zips'\n","cursor.execute(sql) # select the database\n","data = cursor.fetchall()\n","\n","#column names \n","field_names = [i[0] for i in cursor.description]\n","\n","trips_to_and_from_with_zips = pd.DataFrame(data, columns = field_names).to_csv('trips_to_and_from_with_zips.csv')\n","\n","\n","\n","#Combine trips_to_and_from_with_zips with stations_and_features to get the features of the start and end zip codes\n","start_trips = trips_to_and_from_with_zips.rename(columns = {'start_station_name': 'station_name'}).set_index('station_name').join(stations_and_features, on='station_name', lsuffix='', rsuffix='_start').dropna()\n","all_trips_with_features = start_trips.reset_index().rename(columns = {'station_name':'start_station_name', 'end_station_name': 'station_name'}).set_index('station_name').join(stations_and_features, on='station_name', lsuffix='_start', rsuffix='_end').dropna()\n","all_trips_with_features = all_trips_with_features.reset_index().rename(columns = {'station_name':'end_station_name'})\n","\n","#Create csv of trip counts of station pairs \n","all_trips_with_features.to_csv('all_trips_with_features.csv')\n","\n","#Create csv of trip counts for each station\n","trips_by_station.to_csv('trips_by_station.csv')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9p8NAOeCCr5Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}